{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to save and load models. Speculated to be faster for large models in\n",
    "#https://machinelearningmastery.com/save-gradient-boosting-models-xgboost-python/\n",
    "import joblib\n",
    "#XGBoost itself\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that classes/tools from sklearn are imported when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IML2018_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_file_name = 'train10000.npy'\n",
    "train_file_name = 'train_full_Nhardest5.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the file properly for different file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = loadInputAsDF(train_file_name, n = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df['recojet_pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for var in ['recojet_pt', 'recojet_eta', 'recojet_phi', 'recojet_m',\n",
    "#       'recojet_sd_pt', 'recojet_sd_eta', 'recojet_sd_phi', 'recojet_sd_m',\n",
    "#       'n_constituents']:\n",
    "#    print(var)\n",
    "#    sns.jointplot(x='genjet_sd_m', y=var, data=train_df, kind='hex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering (done in a dedicated notebook now) and drop some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropColumns(train_df, printColumns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df.drop('genjet_sd_m', axis=1), train_df['genjet_sd_m'] , test_size=0.30, random_state=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run only if you want to keep jets between 5 and 7 TeV in the test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtest5to7 = (X_test['recojet_pt'] > 5000) & (X_test['recojet_pt'] < 7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = X_test[Xtest5to7]\n",
    "#y_test = y_test[Xtest5to7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X_train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_trans = PCA()\n",
    "pca_trans.fit(X_train)\n",
    "X_train_pca = pca_trans.transform(X_train)\n",
    "X_test_pca = pca_trans.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pd.DataFrame(X_test_pca).corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the XGBoost model and define the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preliminary parameters. will be fine-tuned in the GridSearch\n",
    "xgb_params = {'max_depth': 5, 'learning_rate':0.1, 'n_estimators':100,\n",
    "              'silent':1, 'random_state': 314, 'seed': 314, 'n_jobs':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a comparison of feature importance and extract the optimal number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit(clf, X_train, y_train, early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch to determine the optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is CPU intense! do not try it on the full dataset!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {'max_depth': [3,5,7],\n",
    "               'min_child_weight': [1,3],\n",
    "               'gamma': [0,1e-3,1e-1],\n",
    "               'subsample': [0.6,0.8,1],\n",
    "               'colsample_bytree':[0.6,0.8,1],\n",
    "               'reg_alpha':[0, 1e-3, 1e-1],\n",
    "               'reg_lambda':[1, 1e-1, 1e-3]}\n",
    "gs1 = GridSearchCV(estimator=clf, param_grid=param_test1, \n",
    "                   scoring=make_scorer(evaluate_loss, greater_is_better=False),\n",
    "                   n_jobs=4, cv=5)\n",
    "gs1.fit(X_train, y_train)\n",
    "print(gs1.best_params_)\n",
    "print(gs1.best_score_)\n",
    "print(gs1.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test_list = [{'max_depth': [3,5,7],\n",
    "               'min_child_weight': [1,3]},\n",
    "               {'gamma': [0,1e-3,1e-1]},\n",
    "               {'subsample': [0.6,0.8,1],\n",
    "               'colsample_bytree':[0.6,0.8,1]},\n",
    "               {'reg_alpha':[0, 1e-3, 1e-1],\n",
    "               'reg_lambda':[1, 1e-1, 1e-3]}]\n",
    "for param_test in param_test_list:\n",
    "    gs1 = GridSearchCV(estimator=clf, param_grid=param_test, \n",
    "                       scoring=make_scorer(evaluate_loss, greater_is_better=False),\n",
    "                       n_jobs=4, cv=5,\n",
    "                       verbose=True)\n",
    "    gs1.fit(X_train, y_train)\n",
    "    print(gs1.best_params_)\n",
    "    print(gs1.best_score_)\n",
    "    cv_results.append(gs1.cv_results_)\n",
    "    #print(gs1.cv_results_)\n",
    "    clf.set_params(**(gs1.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the optimised clf object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(gs1, \"gs1_2it.joblib.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_opt_ref1 = gs1.best_estimator_.get_params()\n",
    "xgb_opt_ref1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second iteration of GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test_list = [{'max_depth': [7, 9, 11],\n",
    "               'min_child_weight': [1,3]},\n",
    "               {'gamma': [0,1e-3,1e-1]},\n",
    "               {'reg_alpha':[0, 1e-5],\n",
    "               'reg_lambda':[1, 0.5,2]}]\n",
    "clf.set_params(**xgb_opt_ref1)\n",
    "for param_test in param_test_list:\n",
    "    gs1 = GridSearchCV(estimator=clf, param_grid=param_test, \n",
    "                       scoring=make_scorer(evaluate_loss, greater_is_better=False),\n",
    "                       n_jobs=4, cv=3,\n",
    "                       verbose=True)\n",
    "    gs1.fit(X_train, y_train)\n",
    "    print(gs1.best_params_)\n",
    "    print(gs1.best_score_)\n",
    "    clf.set_params(**(gs1.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test_list = [{'max_depth': [5, 7, 9, 11]},\n",
    "               {'min_child_weight': [1,3]},\n",
    "               {'gamma': [0,1e-3,1e-1]},\n",
    "               {'reg_alpha':[0, 1e-5],\n",
    "               'reg_lambda':[1]}]\n",
    "clf.set_params(**xgb_opt_ref1)\n",
    "for param_test in param_test_list:\n",
    "    gs2 = GridSearchCV(estimator=clf, param_grid=param_test, \n",
    "                       scoring=make_scorer(evaluate_loss, greater_is_better=False),\n",
    "                       n_jobs=4, cv=3,\n",
    "                       verbose=True)\n",
    "    gs2.fit(X_train_pca, y_train)\n",
    "    print(gs2.best_params_)\n",
    "    print(gs2.best_score_)\n",
    "    clf.set_params(**(gs2.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(gs2, \"gs2.joblib.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
